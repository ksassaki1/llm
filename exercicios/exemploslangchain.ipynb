{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste ex. se usa a biblioteca langchain para importar um moldeo de linguagem da openai. Configura-se o modelo com uma chave de api e cria-se\n",
    "uma chain para processar o prompt \"Qual a capital da frança?\", com a resposta sendo exibida na saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/koiti/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: langchain in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (0.3.65)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/koiti/anaconda3/envs/llm/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca Langchain e o modelo de linguagem da OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()                     # procura .env na pasta atual; passe um caminho se estiver fora\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 2. Instancie o modelo de chat:\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key= OPENAI_API_KEY,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Crie o PromptTemplate e a Chain:\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"{question}\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16324/338267425.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run({\"question\": \"Qual é a capital da França?\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A capital da França é Paris.\n"
     ]
    }
   ],
   "source": [
    "# 4. Rode:\n",
    "response = chain.run({\"question\": \"Qual é a capital da França?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemplo de uso de prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A capital do Brasil é Brasília.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Criando um template de prompt\n",
    "template = PromptTemplate.from_template(\"Qual é a capital de {country}?\")\n",
    "\n",
    "# Utilizando o template com o modelo de linguagem\n",
    "prompt = template.format(country=\"Brasil\")\n",
    "response = chain.run(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Por exemplo, imagine que você queira montar um sistema de perguntas e respostas sobre contratos jurídicos armazenados em PDF. Primeiro você carregaria os PDFs com um UnstructuredPDFLoader ou PyPDFLoader, depois dividiria o texto em trechos com RecursiveCharacterTextSplitter, criaria embeddings via OpenAIEmbeddings e indexaria tudo em uma estrutura FAISS. Aí basta ligar um RetrievalQA para que, a cada pergunta, o LangChain recupere os trechos mais relevantes e alimente o LLM num chain de “map-reduce” ou “refine”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF já existe em /home/koiti/Downloads/llm/udhr_booklet_en_web.pdf\n",
      "Total de chunks: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16324/2193829548.py:73: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n",
      "/tmp/ipykernel_16324/2193829548.py:99: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resposta ===\n",
      "O artigo que trata da liberdade de expressão é o Artigo 19 da Declaração Universal dos Direitos Humanos. Ele afirma que \"Todo ser humano tem direito à liberdade de opinião e expressão; esse direito inclui a liberdade de, sem interferência, ter opiniões e de procurar, receber e transmitir informações e ideias por quaisquer meios e independentemente de fronteiras.\" Além disso, o Artigo 20 da mesma declaração garante o direito à liberdade de reunião pacífica e associação. Esses direitos estão intrinsecamente ligados à liberdade, segurança e dignidade de cada indivíduo, conforme estabelecido no Artigo 3 da Declaração Universal dos Direitos Humanos. O Artigo 18 também é relevante, pois garante o direito à liberdade de pensamento, consciência e religião, incluindo a liberdade de mudar de religião ou crença e de manifestar essa religião ou crença em público ou privado, individualmente ou em comunidade.\n",
      "\n",
      "=== Trechos de suporte ===\n",
      "- [48] | Universal Declaration of Human Rights | 40\n",
      "ArticleUNITED\n",
      "NATIONS\n",
      "Everyone has the right to freedom \n",
      "of opinion and expression; this right \n",
      "includes freedom to hold opinions with -\n",
      "out interference a...\n",
      "- [50] | Universal Declaration of Human Rights | 42\n",
      "ArticleUNITED\n",
      "NATIONS\n",
      "(1) Everyone has the right to freedom    \n",
      "of peaceful assembly and association. \n",
      "(2) No one may be compelled to belong \n",
      "to an associa...\n",
      "- [16] | Universal Declaration of Human Rights | 8\n",
      "ArticleUNITED\n",
      "NATIONS\n",
      "Everyone has the right to life, \n",
      "liberty and security of person.03...\n",
      "- [46] | Universal Declaration of Human Rights | 38\n",
      "ArticleUNITED\n",
      "NATIONS\n",
      "Everyone has the right to freedom of \n",
      "thought,  conscience and religion; this \n",
      "right includes freedom to change his religion or belie...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipeline completo de RAG em LangChain que:\n",
    "\n",
    "1. Faz download automático de um PDF público (Declaração Universal dos Direitos Humanos).\n",
    "2. Carrega e divide o PDF em chunks.\n",
    "3. Gera embeddings com OpenAI.\n",
    "4. Armazena os vetores em FAISS.\n",
    "5. Usa um modelo ChatGPT (gpt-3.5-turbo) para responder perguntas a partir do retriever.\n",
    "\n",
    "Pré-requisitos\n",
    "--------------\n",
    "pip install langchain langchain-community \\\n",
    "            openai python-dotenv \\\n",
    "            faiss-cpu tiktoken \\\n",
    "            requests\n",
    "# se preferir CUDA, troque 'faiss-cpu' por 'faiss-gpu' e adicione cudatoolkit compatível.\n",
    "\n",
    "Crie um arquivo .env no mesmo diretório contendo:\n",
    "OPENAI_API_KEY=sk-sua_nova_chave\n",
    "Não compartilhe esse arquivo nem faça commit no Git.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain – loaders, splitters, embeddings, vectorstores, LLM, QA chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 0. Configuração de chaves e caminhos\n",
    "# --------------------------------------------------\n",
    "# Se o .env está no diretório atual, ficamos; caso contrário subimos um nível (ex.: notebooks em exercicios/)\n",
    "ROOT_DIR = Path.cwd() if (Path.cwd() / \".env\").exists() else Path.cwd().parent\n",
    "load_dotenv(ROOT_DIR / \".env\")      # carrega OPENAI_API_KEY sem expor no código\n",
    "\n",
    "PDF_URL  = \"https://www.un.org/en/udhrbook/pdf/udhr_booklet_en_web.pdf\"\n",
    "PDF_PATH = os.path.expanduser(\"~/Downloads/llm/udhr_booklet_en_web.pdf\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Download do PDF, se necessário\n",
    "# --------------------------------------------------\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    print(\"Baixando PDF...\")\n",
    "    resp = requests.get(PDF_URL, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    os.makedirs(os.path.dirname(PDF_PATH), exist_ok=True)\n",
    "    with open(PDF_PATH, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "    print(f\"PDF salvo em {PDF_PATH}\")\n",
    "else:\n",
    "    print(f\"PDF já existe em {PDF_PATH}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Leitura e divisão em trechos\n",
    "# --------------------------------------------------\n",
    "loader   = PyPDFLoader(PDF_PATH)\n",
    "docs     = loader.load()  # lista de Document\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1_000, chunk_overlap=200)\n",
    "chunks   = splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Total de chunks: {len(chunks)}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Embeddings + Faiss\n",
    "# --------------------------------------------------\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever   = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Modelo de linguagem (chat)\n",
    "# --------------------------------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Cadeia de QA por refinamento\n",
    "# --------------------------------------------------\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",        # ou 'stuff' / 'map_reduce'\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Exemplo de consulta\n",
    "# --------------------------------------------------\n",
    "query = \"Qual artigo trata da liberdade de expressão?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"\\n=== Resposta ===\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\n=== Trechos de suporte ===\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- [{doc.metadata.get('page', 'desconhecida')}] {doc.page_content[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este processo pode ser feito usando o chromdb em vez do Faiss tambem, como indicado na celula abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resposta ===\n",
      "O Artigo 19 da Declaração Universal dos Direitos Humanos trata da liberdade de expressão, garantindo que todo ser humano tem o direito à liberdade de opinião e expressão, incluindo a liberdade de buscar, receber e transmitir informações e ideias sem interferência e independentemente de fronteiras. Este direito está intrinsecamente ligado à liberdade de pensamento, consciência e religião, conforme estabelecido no Artigo 18 da mesma declaração. Ambos os artigos são fundamentais para a proteção dos direitos humanos e da democracia.\n",
      "\n",
      "=== Trechos de suporte ===\n",
      "- [pág. 48] | Universal Declaration of Human Rights | 40\n",
      "ArticleUNITED\n",
      "NATIONS\n",
      "Everyone has the right to freedom \n",
      "of opinion and expression; this right \n",
      "includes freedom to hold opinions with -\n",
      "out interference a...\n",
      "- [pág. 50] | Universal Declaration of Human Rights | 42\n",
      "ArticleUNITED\n",
      "NATIONS\n",
      "(1) Everyone has the right to freedom    \n",
      "of peaceful assembly and association. \n",
      "(2) No one may be compelled to belong \n",
      "to an associa...\n",
      "- [pág. 16] | Universal Declaration of Human Rights | 8\n",
      "ArticleUNITED\n",
      "NATIONS\n",
      "Everyone has the right to life, \n",
      "liberty and security of person.03...\n",
      "- [pág. 46] | Universal Declaration of Human Rights | 38\n",
      "ArticleUNITED\n",
      "NATIONS\n",
      "Everyone has the right to freedom of \n",
      "thought,  conscience and religion; this \n",
      "right includes freedom to change his religion or belie...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain – loaders, splitters, embeddings, vectorstores, LLM, QA chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma                  # ← troca o import\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 0. Configuração de chaves e caminhos\n",
    "# --------------------------------------------------\n",
    "ROOT_DIR = Path.cwd() if (Path.cwd() / \".env\").exists() else Path.cwd().parent\n",
    "load_dotenv(ROOT_DIR / \".env\")      # lê OPENAI_API_KEY do .env\n",
    "\n",
    "PDF_URL  = \"https://www.un.org/en/udhrbook/pdf/udhr_booklet_en_web.pdf\"\n",
    "PDF_PATH = os.path.expanduser(\"~/Downloads/llm/udhr_booklet_en_web.pdf\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Download do PDF\n",
    "# --------------------------------------------------\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    resp = requests.get(PDF_URL, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    os.makedirs(os.path.dirname(PDF_PATH), exist_ok=True)\n",
    "    with open(PDF_PATH, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Carregamento e split\n",
    "# --------------------------------------------------\n",
    "loader   = PyPDFLoader(PDF_PATH)\n",
    "docs     = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1_000, chunk_overlap=200)\n",
    "chunks   = splitter.split_documents(docs)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Embeddings + Chroma\n",
    "# --------------------------------------------------\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Se quiser persistir no disco entre execuções, indique persist_directory;\n",
    "# se deixar None (ou omitir), tudo roda apenas em memória.\n",
    "VECTOR_DIR = os.path.expanduser(\"~/Downloads/llm/chroma_udhr\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"udhr\",\n",
    "    persist_directory=VECTOR_DIR               # ← opcional; comenta se não quiser persistir\n",
    ")                                              # ← criação do índice\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Modelo de linguagem\n",
    "# --------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Cadeia de QA\n",
    "# --------------------------------------------------\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Exemplo de consulta\n",
    "# --------------------------------------------------\n",
    "query = \"Qual artigo trata da liberdade de expressão?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"\\n=== Resposta ===\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\n=== Trechos de suporte ===\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- [pág. {doc.metadata.get('page', 'desconhecida')}] {doc.page_content[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para diálogos mais ricos, você pode adicionar memória de contexto. Usar ConversationBufferMemory faz com que cada troca seja empilhada e reapresentada ao LLM; usar ConversationSummaryMemory resume a conversa antiga para economizar tokens. Com isso, o assistente “lembra” de detalhes sem precisar reenviar tudo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF já existe em /home/koiti/Downloads/llm/udhr_booklet_en_web.pdf\n",
      "Total de chunks: 40\n",
      "\n",
      "Pergunta 1:\n",
      "Os direitos mencionados nos trechos fornecidos são parte da Declaração Universal dos Direitos Humanos, adotada e proclamada pela Assembleia Geral das Nações Unidas em 1948.\n",
      "\n",
      "Pergunta 2:\n",
      "O artigo da Declaração Universal dos Direitos Humanos que trata da liberdade de expressão é o Artigo 19. Ele afirma que \"Todo ser humano tem direito à liberdade de opinião e expressão; esse direito inclui a liberdade de, sem interferência, ter opiniões e de procurar, receber e transmitir informações e ideias por quaisquer meios e independentemente de fronteiras.\"\n",
      "\n",
      "=== Histórico ===\n",
      "User: Quem é o responsável por esses direitos?...\n",
      "AI: Os direitos mencionados nos trechos fornecidos são parte da Declaração Universal...\n",
      "User: E qual artigo trata da liberdade de expressão?...\n",
      "AI: O artigo da Declaração Universal dos Direitos Humanos que trata da liberdade de ...\n",
      "\n",
      "=== Fontes ===\n",
      "[p.48] | Universal Declaration of Human Rights | 40 ArticleUNITED NATIONS Everyone has the right to freedom  of opinion and exp…\n",
      "[p.50] | Universal Declaration of Human Rights | 42 ArticleUNITED NATIONS (1) Everyone has the right to freedom     of peaceful…\n",
      "[p.16] | Universal Declaration of Human Rights | 8 ArticleUNITED NATIONS Everyone has the right to life,  liberty and security …\n",
      "[p.70] | Universal Declaration of Human Rights | 62 ArticleUNITED NATIONS Nothing in this Declaration may be  interpreted as im…\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipeline Conversational RAG — Declaração Universal dos Direitos Humanos\n",
    "\n",
    "1. Baixa o PDF da ONU (se ainda não existir).\n",
    "2. Constrói FAISS + embeddings OpenAI.\n",
    "3. Usa ConversationalRetrievalChain com memória de buffer.\n",
    "\n",
    "Requisitos\n",
    "----------\n",
    "pip install langchain langchain-community \\\n",
    "            openai python-dotenv \\\n",
    "            faiss-cpu tiktoken \\\n",
    "            requests\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 0. Ambiente\n",
    "# --------------------------------------------------\n",
    "# Se o .env está no diretório atual, ficamos; caso contrário subimos um nível (ex.: notebooks em exercicios/)\n",
    "ROOT_DIR = Path.cwd() if (Path.cwd() / \".env\").exists() else Path.cwd().parent\n",
    "load_dotenv(ROOT_DIR / \".env\")      # carrega OPENAI_API_KEY sem expor no código\n",
    "\n",
    "PDF_URL  = \"https://www.un.org/en/udhrbook/pdf/udhr_booklet_en_web.pdf\"\n",
    "PDF_PATH = os.path.expanduser(\"~/Downloads/llm/udhr_booklet_en_web.pdf\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Download do PDF\n",
    "# --------------------------------------------------\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    print(\"Baixando PDF...\")\n",
    "    r = requests.get(PDF_URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    os.makedirs(os.path.dirname(PDF_PATH), exist_ok=True)\n",
    "    with open(PDF_PATH, \"wb\") as fp:\n",
    "        fp.write(r.content)\n",
    "    print(f\"PDF salvo em {PDF_PATH}\")\n",
    "else:\n",
    "    print(f\"PDF já existe em {PDF_PATH}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Carrega e divide\n",
    "# --------------------------------------------------\n",
    "loader   = PyPDFLoader(PDF_PATH)\n",
    "docs     = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1_000, chunk_overlap=200)\n",
    "chunks   = splitter.split_documents(docs)\n",
    "print(f\"Total de chunks: {len(chunks)}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Embeddings + FAISS\n",
    "# --------------------------------------------------\n",
    "embeddings  = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever   = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. LLM e memória\n",
    "# --------------------------------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    output_key=\"answer\",      \n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chat_rag = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Diálogo de teste\n",
    "# --------------------------------------------------\n",
    "print(\"\\nPergunta 1:\")\n",
    "resp1 = chat_rag({\"question\": \"Quem é o responsável por esses direitos?\"})\n",
    "print(resp1[\"answer\"])\n",
    "\n",
    "print(\"\\nPergunta 2:\")\n",
    "resp2 = chat_rag({\"question\": \"E qual artigo trata da liberdade de expressão?\"})\n",
    "print(resp2[\"answer\"])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Histórico e fontes\n",
    "# --------------------------------------------------\n",
    "print(\"\\n=== Histórico ===\")\n",
    "for msg in memory.chat_memory.messages:\n",
    "    role = \"User\" if msg.type == \"human\" else \"AI\"\n",
    "    print(f\"{role}: {msg.content[:80]}...\")\n",
    "\n",
    "print(\"\\n=== Fontes ===\")\n",
    "for doc in resp2[\"source_documents\"]:\n",
    "    page = doc.metadata.get(\"page\", \"desconhecida\")\n",
    "    snippet = doc.page_content.replace(\"\\n\", \" \")[:120]\n",
    "    print(f\"[p.{page}] {snippet}…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de chunks: 40\n",
      "\n",
      "Pergunta 1:\n",
      "Os direitos mencionados nos trechos fornecidos são garantidos pela Declaração Universal dos Direitos Humanos, que é um documento adotado pela Assembleia Geral das Nações Unidas.\n",
      "\n",
      "Pergunta 2:\n",
      "O artigo da Declaração Universal dos Direitos Humanos que trata da liberdade de expressão é o Artigo 19. Ele afirma que \"Todo ser humano tem direito à liberdade de opinião e expressão\".\n",
      "\n",
      "=== Histórico ===\n",
      "User: Quem é o responsável por esses direitos?…\n",
      "AI: Os direitos mencionados nos trechos fornecidos são garantidos pela Declaração Un…\n",
      "User: E qual artigo trata da liberdade de expressão?…\n",
      "AI: O artigo da Declaração Universal dos Direitos Humanos que trata da liberdade de …\n",
      "\n",
      "=== Fontes ===\n",
      "[p.48] | Universal Declaration of Human Rights | 40 ArticleUNITED NATIONS Everyone has the right to freedom  of opinion and exp…\n",
      "[p.48] | Universal Declaration of Human Rights | 40 ArticleUNITED NATIONS Everyone has the right to freedom  of opinion and exp…\n",
      "[p.50] | Universal Declaration of Human Rights | 42 ArticleUNITED NATIONS (1) Everyone has the right to freedom     of peaceful…\n",
      "[p.50] | Universal Declaration of Human Rights | 42 ArticleUNITED NATIONS (1) Everyone has the right to freedom     of peaceful…\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipeline Conversational RAG — Declaração Universal dos Direitos Humanos\n",
    "versão ChromaDB + OpenAI + memória de buffer\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma                   # ← novo import\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 0. Ambiente\n",
    "# --------------------------------------------------\n",
    "ROOT_DIR = Path.cwd() if (Path.cwd() / \".env\").exists() else Path.cwd().parent\n",
    "load_dotenv(ROOT_DIR / \".env\")                 # lê OPENAI_API_KEY\n",
    "\n",
    "PDF_URL  = \"https://www.un.org/en/udhrbook/pdf/udhr_booklet_en_web.pdf\"\n",
    "PDF_PATH = os.path.expanduser(\"~/Downloads/llm/udhr_booklet_en_web.pdf\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Download do PDF\n",
    "# --------------------------------------------------\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    print(\"Baixando PDF…\")\n",
    "    r = requests.get(PDF_URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    os.makedirs(os.path.dirname(PDF_PATH), exist_ok=True)\n",
    "    with open(PDF_PATH, \"wb\") as fp:\n",
    "        fp.write(r.content)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Carrega e divide\n",
    "# --------------------------------------------------\n",
    "loader   = PyPDFLoader(PDF_PATH)\n",
    "docs     = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1_000, chunk_overlap=200)\n",
    "chunks   = splitter.split_documents(docs)\n",
    "print(f\"Total de chunks: {len(chunks)}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Embeddings + Chroma\n",
    "# --------------------------------------------------\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Se quiser reutilizar o índice entre execuções, defina persist_directory\n",
    "# (o caminho abaixo é só um exemplo; remova o parâmetro para rodar em memória)\n",
    "VECTOR_DIR = os.path.expanduser(\"~/Downloads/llm/chroma_udhr\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"udhr\",\n",
    "    persist_directory=VECTOR_DIR          # comente esta linha se não precisar persistir\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. LLM e memória de conversa\n",
    "# --------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    output_key=\"answer\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chat_rag = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Diálogo de teste\n",
    "# --------------------------------------------------\n",
    "print(\"\\nPergunta 1:\")\n",
    "resp1 = chat_rag({\"question\": \"Quem é o responsável por esses direitos?\"})\n",
    "print(resp1[\"answer\"])\n",
    "\n",
    "print(\"\\nPergunta 2:\")\n",
    "resp2 = chat_rag({\"question\": \"E qual artigo trata da liberdade de expressão?\"})\n",
    "print(resp2[\"answer\"])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Histórico e fontes\n",
    "# --------------------------------------------------\n",
    "print(\"\\n=== Histórico ===\")\n",
    "for msg in memory.chat_memory.messages:\n",
    "    role = \"User\" if msg.type == \"human\" else \"AI\"\n",
    "    print(f\"{role}: {msg.content[:80]}…\")\n",
    "\n",
    "print(\"\\n=== Fontes ===\")\n",
    "for doc in resp2[\"source_documents\"]:\n",
    "    page = doc.metadata.get(\"page\", \"desconhecida\")\n",
    "    snippet = doc.page_content.replace(\"\\n\", \" \")[:120]\n",
    "    print(f\"[p.{page}] {snippet}…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se o seu caso exigir decisões dinâmicas – por exemplo, primeiro buscar na internet, depois consultar uma base de dados interna, depois gerar um relatório – você pode criar um agente que receba várias “tools” (funções Python, chamadas HTTP, queries SQL) e deixe que o modelo opine qual deve chamar a cada passo. No modo ZERO_SHOT_REACT_DESCRIPTION, o LangChain cria um prompt invisível que enumera os tools disponíveis e suas descrições. O modelo de linguagem “raciocina” passo a passo (cotação Thought/Action/Observation) e escolhe o tool cujo nome e descrição melhor se encaixam no que precisa fazer para responder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resposta 1 ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to compare Article 19 of the Universal Declaration of Human Rights with the clause Penalty_LateFees in contract 42 to see if there is a conflict.\n",
      "Action: udhr_search\n",
      "Action Input: \"Article 19 Universal Declaration of Human Rights\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe additional context provided does not directly relate to Article 19 of the Universal Declaration of Human Rights, which focuses on freedom of opinion and expression. Therefore, the original answer remains relevant and does not need to be refined with the new information.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to search for the specific clause Penalty_LateFees in contract 42 to compare with Article 19 of the UDHR.\n",
      "Action: contract_db\n",
      "Action Input: \"SELECT Penalty_LateFees FROM Contract WHERE ContractNumber = 42\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mErro SQL: no such table: Contract\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to correct the SQL query to ensure it retrieves the clause Penalty_LateFees from contract 42.\n",
      "Action: contract_db\n",
      "Action Input: \"SELECT Penalty_LateFees FROM Contracts WHERE ContractNumber = 42\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mErro SQL: no such table: Contracts\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to verify the table name in the contract database to ensure I am querying the correct table.\n",
      "Action: contract_db\n",
      "Action Input: \"SHOW TABLES\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mErro SQL: near \"SHOW\": syntax error\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to check the available tables in the contract database using a different method.\n",
      "Action: contract_db\n",
      "Action Input: \"SELECT name FROM sqlite_master WHERE type='table';\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m0 linhas → []…\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to verify if the contract database is accessible and contains the necessary information to compare with Article 19 of the UDHR.\n",
      "Action: web_search\n",
      "Action Input: \"Contract 42 Penalty_LateFees clause\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNenhum resultado encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI was unable to retrieve the necessary information from the contract database or the web search to compare Article 19 of the UDHR with the Penalty_LateFees clause in contract 42.\n",
      "Final Answer: Unable to determine if there is a conflict between Article 19 of the UDHR and the Penalty_LateFees clause in contract 42 due to lack of information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Unable to determine if there is a conflict between Article 19 of the UDHR and the Penalty_LateFees clause in contract 42 due to lack of information.\n",
      "\n",
      "--- Resposta 2 ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mPreciso pesquisar informações recentes na web para encontrar a resposta.\n",
      "Action: web_search\n",
      "Action Input: \"Countries that voted against UN resolution 2023 freedom of expression\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNenhum resultado encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNão consegui encontrar informações recentes sobre os países que votaram contra a resolução da ONU de 2023 sobre liberdade de expressão. Vou tentar outra abordagem.\n",
      "Action: web_search\n",
      "Action Input: \"UN resolution 2023 freedom of expression voting results\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNenhum resultado encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNão consegui encontrar informações recentes sobre os países que votaram contra a resolução da ONU de 2023 sobre liberdade de expressão. Vou tentar outra abordagem.\n",
      "Action: web_search\n",
      "Action Input: \"UN resolution 2023 freedom of expression voting details\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNenhum resultado encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNão consegui encontrar informações recentes sobre os países que votaram contra a resolução da ONU de 2023 sobre liberdade de expressão. Vou tentar outra abordagem.\n",
      "Action: web_search\n",
      "Action Input: \"UN resolution 2023 freedom of expression voting countries\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNenhum resultado encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNão consegui encontrar informações recentes sobre os países que votaram contra a resolução da ONU de 2023 sobre liberdade de expressão. Vou tentar outra abordagem.\n",
      "Action: web_search\n",
      "Action Input: \"UN resolution 2023 freedom of expression voting countries list\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNenhum resultado encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNão consegui encontrar informações recentes sobre os países que votaram contra a resolução da ONU de 2023 sobre liberdade de expressão. Vou tentar outra abordagem.\n",
      "Action: udhr_search\n",
      "Action Input: \"Quais países votaram contra a resolução da ONU de 2023 sobre liberdade de expressão?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDesculpe, mas a informação fornecida sobre o Artigo 12 da Declaração Universal dos Direitos Humanos não está diretamente relacionada com a resolução da ONU de 2023 sobre liberdade de expressão. Se você tiver mais informações específicas sobre a resolução em questão, por favor, me informe para que eu possa ajudar a responder à sua pergunta original.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNão consegui encontrar a resposta usando as ferramentas disponíveis. Talvez seja necessário buscar em fontes mais específicas ou aguardar por informações mais detalhadas sobre a resolução da ONU de 2023 sobre liberdade de expressão.\n",
      "Final Answer: Não foi possível encontrar os países que votaram contra a resolução da ONU de 2023 sobre liberdade de expressão.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Não foi possível encontrar os países que votaram contra a resolução da ONU de 2023 sobre liberdade de expressão.\n"
     ]
    }
   ],
   "source": [
    "import os, requests, sqlite3          # sqlite = exemplo de BD local\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain – mesmo fluxo de antes\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 0. Ambiente e PDF da Declaração\n",
    "# --------------------------------------------------\n",
    "ROOT_DIR = Path.cwd() if (Path.cwd() / \".env\").exists() else Path.cwd().parent\n",
    "load_dotenv(ROOT_DIR / \".env\")\n",
    "\n",
    "PDF_URL  = \"https://www.un.org/en/udhrbook/pdf/udhr_booklet_en_web.pdf\"\n",
    "PDF_PATH = os.path.expanduser(\"~/Downloads/llm/udhr_booklet_en_web.pdf\")\n",
    "\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    r = requests.get(PDF_URL, timeout=30); r.raise_for_status()\n",
    "    os.makedirs(os.path.dirname(PDF_PATH), exist_ok=True)\n",
    "    with open(PDF_PATH, \"wb\") as fp: fp.write(r.content)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Indexa a UDHR\n",
    "# --------------------------------------------------\n",
    "loader   = PyPDFLoader(PDF_PATH)\n",
    "docs     = loader.load()\n",
    "chunks   = RecursiveCharacterTextSplitter(\n",
    "              chunk_size=1_000, chunk_overlap=200).split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "retriever   = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "qa_chain_udhr = RetrievalQA.from_chain_type(\n",
    "                   llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "                   chain_type=\"refine\",\n",
    "                   retriever=retriever,\n",
    "                   return_source_documents=False)\n",
    "\n",
    "def udhr_tool(q: str) -> str:\n",
    "    return qa_chain_udhr.run(q)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Tool: busca web (exemplo mínimo com DuckDuckGo JSON)\n",
    "#    → troque pela sua API/SerpAPI preferida\n",
    "# --------------------------------------------------\n",
    "def search_web(query: str) -> str:\n",
    "    api = \"https://duckduckgo.com/js/spice/search\"\n",
    "    resp = requests.get(api, params={\"q\": query, \"format\": \"json\"}, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    # resposta simplificada: primeiro snippet encontrado\n",
    "    data = resp.json()\n",
    "    if data.get(\"Results\"):\n",
    "        return data[\"Results\"][0][\"Text\"]\n",
    "    return \"Nenhum resultado encontrado.\"\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Tool: consulta SQL (sqlite apenas para ilustrar)\n",
    "# --------------------------------------------------\n",
    "DB_PATH = os.path.expanduser(\"~/Downloads/llm/contracts.db\")\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "def query_sql(sql: str) -> str:\n",
    "    try:\n",
    "        cur = conn.execute(sql)\n",
    "        rows = cur.fetchall()\n",
    "        return f\"{len(rows)} linhas → {rows[:3]}…\"  # mostra no máximo 3\n",
    "    except Exception as e:\n",
    "        return f\"Erro SQL: {e}\"\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Agente com três tools\n",
    "# --------------------------------------------------\n",
    "tools = [\n",
    "    Tool(name=\"udhr_search\",\n",
    "         description=\"Responde perguntas sobre a Declaração Universal dos Direitos Humanos.\",\n",
    "         func=udhr_tool),\n",
    "    Tool(name=\"web_search\",\n",
    "         description=\"Pesquisa informações públicas recentes na web.\",\n",
    "         func=search_web),\n",
    "    Tool(name=\"contract_db\",\n",
    "         description=\"Consulta cláusulas e multas no banco de dados de contratos; aceita SQL SELECT.\",\n",
    "         func=query_sql),\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Exemplos de perguntas que exigem ferramentas diferentes\n",
    "# --------------------------------------------------\n",
    "# a) Precisa da UDHR + SQL\n",
    "q1 = (\"Compare o Artigo 19 da Declaração Universal dos Direitos Humanos \"\n",
    "      \"com a cláusula Penalty_LateFees do contrato 42 e diga se há conflito.\")\n",
    "print(\"\\n--- Resposta 1 ---\")\n",
    "print(agent.run(q1))\n",
    "\n",
    "# b) Precisa de pesquisa web (resolução recente da ONU)\n",
    "q2 = (\"Quais países votaram contra a resolução da ONU de 2023 sobre liberdade de expressão? \"\n",
    "      \"Cite a fonte resumidamente.\")\n",
    "print(\"\\n--- Resposta 2 ---\")\n",
    "print(agent.run(q2))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
